{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashionmnist_gans.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9FkaOfWwawu"
      },
      "source": [
        "!pip install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from imutils import build_montages\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBrLwCtN5kqy"
      },
      "source": [
        "### Function to display images in Jupyter Notebooks and Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRw969Dp5Kdm"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "  # convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image, aspect=\"auto\")\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Implementing our “generator” and “discriminator” with Keras and TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwHgIBergNRm"
      },
      "source": [
        "class DCGAN:\n",
        "\t@staticmethod\n",
        "\tdef build_generator(dim, depth, channels=1, inputDim=100,\n",
        "\t\toutputDim=512):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (dim, dim, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "        # first set of FC => RELU => BN layers\n",
        "\t\tmodel.add(Dense(input_dim=inputDim, units=outputDim))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\n",
        "\t\t# second set of FC => RELU => BN layers, this time preparing\n",
        "\t\t# the number of FC nodes to be reshaped into a volume\n",
        "\t\tmodel.add(Dense(dim * dim * depth))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "  \n",
        "  \t\t# reshape the output of the previous layer set, upsample +\n",
        "\t\t# apply a transposed convolution, RELU, and BN\n",
        "\t\tmodel.add(Reshape(inputShape))\n",
        "\t\tmodel.add(Conv2DTranspose(32, (5, 5), strides=(2, 2),\n",
        "\t\t\tpadding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "  \n",
        "  \t\t# apply another upsample and transposed convolution, but\n",
        "\t\t# this time output the TANH activation\n",
        "\t\tmodel.add(Conv2DTranspose(channels, (5, 5), strides=(2, 2),\n",
        "\t\t\tpadding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"tanh\"))\n",
        "\n",
        "\t\t# return the generator model\n",
        "\t\treturn model\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef build_discriminator(width, height, depth, alpha=0.2):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\"\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\n",
        "\t\t# first set of CONV => RELU layers\n",
        "\t\tmodel.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(LeakyReLU(alpha=alpha))\n",
        "\n",
        "\t\t# second set of CONV => RELU layers\n",
        "\t\tmodel.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
        "\t\tmodel.add(LeakyReLU(alpha=alpha))\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(512))\n",
        "\t\tmodel.add(LeakyReLU(alpha=alpha))\n",
        "\n",
        "\t\t# sigmoid layer outputting a single value\n",
        "\t\tmodel.add(Dense(1))\n",
        "\t\tmodel.add(Activation(\"sigmoid\"))\n",
        "\n",
        "\t\t# return the discriminator model\n",
        "\t\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oDMMjdvg13X"
      },
      "source": [
        "### Implementing our GAN training script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc"
      },
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-o\", \"--output\", required=True,\n",
        "#\thelp=\"path to output directory\")\n",
        "#p.add_argument(\"-e\", \"--epochs\", type=int, default=50,\n",
        "#\thelp=\"# epochs to train for\")\n",
        "#ap.add_argument(\"-b\", \"--batch-size\", type=int, default=128,\n",
        "#\thelp=\"batch size for training\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "\t\"output\": \"output\",\n",
        "\t\"epochs\": 50,\n",
        "\t\"batch_size\": 128\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgwh3CUjhe6j"
      },
      "source": [
        "# store the epochs and batch size in convenience variables, then\n",
        "# initialize our learning rate\n",
        "NUM_EPOCHS = args[\"epochs\"]\n",
        "BATCH_SIZE = args[\"batch_size\"]\n",
        "INIT_LR = 2e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfCBguOqhjKq"
      },
      "source": [
        "# load the Fashion MNIST dataset and stack the training and testing\n",
        "# data points so we have additional training data\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "((trainX, _), (testX, _)) = fashion_mnist.load_data()\n",
        "trainImages = np.concatenate([trainX, testX])\n",
        "\n",
        "# add in an extra dimension for the channel and scale the images\n",
        "# into the range [-1, 1] (which is the range of the tanh\n",
        "# function)\n",
        "trainImages = np.expand_dims(trainImages, axis=-1)\n",
        "trainImages = (trainImages.astype(\"float\") - 127.5) / 127.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi4dCP3khkdo"
      },
      "source": [
        "# build the generator\n",
        "print(\"[INFO] building generator...\")\n",
        "gen = DCGAN.build_generator(7, 64, channels=1)\n",
        "\n",
        "# build the discriminator\n",
        "print(\"[INFO] building discriminator...\")\n",
        "disc = DCGAN.build_discriminator(28, 28, 1)\n",
        "discOpt = Adam(lr=INIT_LR, beta_1=0.5, decay=INIT_LR / NUM_EPOCHS)\n",
        "disc.compile(loss=\"binary_crossentropy\", optimizer=discOpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC-vCwEhhnKE"
      },
      "source": [
        "# build the adversarial model by first setting the discriminator to\n",
        "# *not* be trainable, then combine the generator and discriminator\n",
        "# together\n",
        "print(\"[INFO] building GAN...\")\n",
        "disc.trainable = False\n",
        "ganInput = Input(shape=(100,))\n",
        "ganOutput = disc(gen(ganInput))\n",
        "gan = Model(ganInput, ganOutput)\n",
        "\n",
        "# compile the GAN\n",
        "ganOpt = Adam(lr=INIT_LR, beta_1=0.5, decay=INIT_LR / NUM_EPOCHS)\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=discOpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPes5dYwhqL5"
      },
      "source": [
        "# randomly generate some benchmark noise so we can consistently\n",
        "# visualize how the generative modeling is learning\n",
        "print(\"[INFO] starting training...\")\n",
        "benchmarkNoise = np.random.uniform(-1, 1, size=(256, 100))\n",
        "\n",
        "# loop over the epochs\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "\t# show epoch information and compute the number of batches per\n",
        "\t# epoch\n",
        "\tprint(\"[INFO] starting epoch {} of {}...\".format(epoch + 1,\n",
        "\t\tNUM_EPOCHS))\n",
        "\tbatchesPerEpoch = int(trainImages.shape[0] / BATCH_SIZE)\n",
        "\n",
        "\t# loop over the batches\n",
        "\tfor i in range(0, batchesPerEpoch):\n",
        "\t\t# initialize an (empty) output path\n",
        "\t\tp = None\n",
        "\n",
        "\t\t# select the next batch of images, then randomly generate\n",
        "\t\t# noise for the generator to predict on\n",
        "\t\timageBatch = trainImages[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
        "\t\tnoise = np.random.uniform(-1, 1, size=(BATCH_SIZE, 100))\n",
        "\n",
        "\t\t# generate images using the noise + generator model\n",
        "\t\tgenImages = gen.predict(noise, verbose=0)\n",
        "\n",
        "\t\t# concatenate the *actual* images and the *generated* images,\n",
        "\t\t# construct class labels for the discriminator, and shuffle\n",
        "\t\t# the data\n",
        "\t\tX = np.concatenate((imageBatch, genImages))\n",
        "\t\ty = ([1] * BATCH_SIZE) + ([0] * BATCH_SIZE)\n",
        "\t\ty = np.reshape(y, (-1,))\n",
        "\t\t(X, y) = shuffle(X, y)\n",
        "\n",
        "\t\t# train the discriminator on the data\n",
        "\t\tdiscLoss = disc.train_on_batch(X, y)\n",
        "  \n",
        "\t\t# let's now train our generator via the adversarial model by\n",
        "\t\t# (1) generating random noise and (2) training the generator\n",
        "\t\t# with the discriminator weights frozen\n",
        "\t\tnoise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
        "\t\tfakeLabels = [1] * BATCH_SIZE\n",
        "\t\tfakeLabels = np.reshape(fakeLabels, (-1,))\n",
        "\t\tganLoss = gan.train_on_batch(noise, fakeLabels)\n",
        "\n",
        "\t\t# check to see if this is the end of an epoch, and if so,\n",
        "\t\t# initialize the output path\n",
        "\t\tif i == batchesPerEpoch - 1:\n",
        "\t\t\tp = [args[\"output\"], \"epoch_{}_output.png\".format(\n",
        "\t\t\t\tstr(epoch + 1).zfill(4))]\n",
        "\n",
        "\t\t# otherwise, check to see if we should visualize the current\n",
        "\t\t# batch for the epoch\n",
        "\t\telse:\n",
        "\t\t\t# create more visualizations early in the training\n",
        "\t\t\t# process\n",
        "\t\t\tif epoch < 10 and i % 25 == 0:\n",
        "\t\t\t\tp = [args[\"output\"], \"epoch_{}_step_{}.png\".format(\n",
        "\t\t\t\t\tstr(epoch + 1).zfill(4), str(i).zfill(5))]\n",
        "\n",
        "\t\t\t# visualizations later in the training process are less\n",
        "\t\t\t# interesting\n",
        "\t\t\telif epoch >= 10 and i % 100 == 0:\n",
        "\t\t\t\tp = [args[\"output\"], \"epoch_{}_step_{}.png\".format(\n",
        "\t\t\t\t\tstr(epoch + 1).zfill(4), str(i).zfill(5))]\n",
        "\n",
        "\t\t# check to see if we should visualize the output of the\n",
        "\t\t# generator model on our benchmark data\n",
        "\t\tif p is not None:\n",
        "\t\t\t# show loss information\n",
        "\t\t\tprint(\"[INFO] Step {}_{}: discriminator_loss={:.6f}, \"\n",
        "\t\t\t\t\"adversarial_loss={:.6f}\".format(epoch + 1, i,\n",
        "\t\t\t\t\tdiscLoss, ganLoss))\n",
        "\n",
        "\t\t\t# make predictions on the benchmark noise, scale it back\n",
        "\t\t\t# to the range [0, 255], and generate the montage\n",
        "\t\t\timages = gen.predict(benchmarkNoise)\n",
        "\t\t\timages = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
        "\t\t\timages = np.repeat(images, 3, axis=-1)\n",
        "\t\t\tvis = build_montages(images, (28, 28), (16, 16))[0]\n",
        "\n",
        "\t\t\t# write the visualization to disk\n",
        "\t\t\tp = os.path.sep.join(p)\n",
        "\t\t\tcv2.imwrite(p, vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuptzEe3iMUX"
      },
      "source": [
        "### Visualizing our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4BrHJaGiLdC"
      },
      "source": [
        "# define path to our final epoch results\n",
        "filename = \"epoch_{}_output.png\".format(str(args[\"epochs\"]).zfill(4))\n",
        "resultPath = os.path.join(args[\"output\"], filename)\n",
        "\n",
        "# load the result image and display it\n",
        "image = cv2.imread(resultPath)\n",
        "plt_imshow(\"result\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogkNauArL6u"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*GANs with Keras and TensorFlow*](https://www.pyimagesearch.com/2020/11/16/gans-with-keras-and-tensorflow/) published on 2020-11-16."
      ]
    }
  ]
}